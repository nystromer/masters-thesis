{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __INIT__ \n",
    "\n",
    "import medleydb as mdb\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from os import path\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "HOME_PATH = path.expanduser(\"~\")\n",
    "\n",
    "DATA_PATH = path.join(HOME_PATH, 'data', 'preprocessed')\n",
    "if not os.path.exists(DATA_PATH):\n",
    "        os.makedirs(DATA_PATH)   \n",
    "        \n",
    "SOURCE_PATH = path.join(DATA_PATH, 'source_ids')\n",
    "if not os.path.exists(SOURCE_PATH):\n",
    "        os.makedirs(SOURCE_PATH) \n",
    "        \n",
    "MIX_PATH = path.join(HOME_PATH, 'data', 'mixes')\n",
    "if not os.path.exists(MIX_PATH):\n",
    "        os.makedirs(MIX_PATH) \n",
    "\n",
    "# Ã„ndra till detta i en paketstruktur\n",
    "# DATA_PATH = path.join(path.dirname(__file__), 'data', 'preprocessed')\n",
    "\n",
    "# Based off of OpenMICs taxonomy discussions and the MedleyDB taxonomy yaml\n",
    "OPENMIC_TO_MEDLEY = {\"drums\" : [\"drum set\"],\n",
    "                     \"bass\" : [\"electric bass\", \"double bass\"],\n",
    "                     \"guitar\" : [\"distorted electric guitar\", \"clean electric guitar\", \"acoustic guitar\"], \n",
    "                     \"voice\" : [\"male singer\", \"female singer\", \"male speaker\", \"female speaker\",\n",
    "                                \"male rapper\", \"female rapper\", \"beatboxing\", \"vocalists\", \"choir\",\n",
    "                                \"male screamer\", \"female screamer\"], \n",
    "                     \"piano\" : [\"piano\", \"tack piano\", \"electric piano\"],\n",
    "                     \"synthesizer\" : [\"synthesizer\"],\n",
    "                     #\"organ\" : [\"pipe organ\", \"electric organ\"],\n",
    "                     #\"accordion\" : [\"accordion\"],\n",
    "                     #\"banjo\" : [\"banjo\"], \n",
    "                     \"cello\" : [\"cello\", \"cello section\"], \n",
    "                     \"clarinet\" : [\"clarinet\", \"clarinet section\", \"bass clarinet\"], \n",
    "                     \"cymbals\" : [\"cymbal\"],\n",
    "                     \"flute\" : [\"flute\", \"dizi\", \"flute\", \"flute section\", \"piccolo\",\n",
    "                                \"bamboo flute\", \"panpipes\", \"recorder\"],\n",
    "                     \"mallet_percussion\" : [\"xylophone\", \"vibraphone\", \"glockenspiel\", \"marimba\"],\n",
    "                     \"mandolin\" : [\"mandolin\"],\n",
    "                     \"saxophone\": [\"alto saxophone\", \"baritone saxophone\", \"tenor saxophone\", \"soprano saxophone\"], \n",
    "                     \"trombone\": [\"trombone\", \"trombone section\"], \n",
    "                     \"trumpet\" : [\"trumpet\", \"trumpet section\"],\n",
    "                     #\"ukulele\" : [\"ukulele\"], \n",
    "                     \"violin\" : [\"violin\", \"violin seciton\"]} \n",
    "\n",
    "INSTRUMENTS = OPENMIC_TO_MEDLEY.keys()\n",
    "INSTRUMENT_INDEX = {key : i for i, (key, _) in enumerate(OPENMIC_TO_MEDLEY.items())}\n",
    "MEDLEY_TO_OPENMIC = {v: k for k, v_list in OPENMIC_TO_MEDLEY.items() for v in v_list}\n",
    "MEDLEY_TO_INDEX = {k: INSTRUMENT_INDEX[v] for k, v in MEDLEY_TO_OPENMIC.items()}\n",
    "REV_INSTRUMENT_INDEX = {v: k for k, v in INSTRUMENT_INDEX.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S01': ['bass'], 'S02': ['drums'], 'S03': ['guitar'], 'S04': ['guitar']}\n",
      "Help on MultiTrack in module medleydb.multitrack object:\n",
      "\n",
      "class MultiTrack(builtins.object)\n",
      " |  MultiTrack(track_id)\n",
      " |  \n",
      " |  MultiTrack Class definition.\n",
      " |  \n",
      " |  This class loads all available metadata, annotations, and filepaths for a\n",
      " |  given multitrack directory.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  track_id : str\n",
      " |      Track id in format 'Artist_Title'.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  artist : str\n",
      " |      The artist of the multitrack\n",
      " |  title : str\n",
      " |      The title of the multitrack\n",
      " |  track_id : str\n",
      " |      The unique identifier of the multitrack. In the form 'Artist_Title'\n",
      " |  annotation_dir : str\n",
      " |      Path to multitrack's annotation directory\n",
      " |  audio_path : str\n",
      " |      Path to multitrack's top level audio directory\n",
      " |  mix_path : str\n",
      " |      Path to multitrack's mix file.\n",
      " |  melody_rankings : dictionary\n",
      " |      Dictionary of melody rankings keyed by stem id\n",
      " |  melody1_fpath : str\n",
      " |      Path to melody 1 annotation file\n",
      " |  melody2_fpath : str\n",
      " |      Path to melody 2 annotation file\n",
      " |  melody3_fpath : str\n",
      " |      Path to melody 3 annotation file\n",
      " |  melody_intervals_fpath : str\n",
      " |      Path to melody intervals file\n",
      " |  melody_rankings_fpath : str\n",
      " |      Path to melody rankings file\n",
      " |  activation_conf_fpath : str\n",
      " |      Path to original activation confidence file\n",
      " |  activation_conf_v2_fpath : str\n",
      " |      Path to version 2 activation confidence file\n",
      " |  source_id_fpath : str\n",
      " |      Path to source id file\n",
      " |  mixing_coefficients : dictionary\n",
      " |      Dictionary of mixing weights keyed by stem id\n",
      " |  stems : dictionary\n",
      " |      Dictionary of stem Track objects keyed by stem id\n",
      " |  raw_audio : dictionary\n",
      " |      Dictionary of dictionaries keyed by stem id\n",
      " |  stem_instruments : list\n",
      " |      List of stem instrument labels\n",
      " |  raw_instruments : list\n",
      " |      List of raw audio instrument labels\n",
      " |  duration : float or None\n",
      " |      Duration of mix, or None if audio cannot be found\n",
      " |  is_excerpt : bool\n",
      " |      True if multitrack is an excerpt\n",
      " |  has_bleed : bool\n",
      " |      True if multitrack has bleed\n",
      " |  is_instrumental : bool\n",
      " |      True if multitrack is instrumental\n",
      " |  origin : str\n",
      " |      Origin of multitrack\n",
      " |  genre : str\n",
      " |      Genre of multitrack\n",
      " |  metadata_version : str\n",
      " |      Metadata version\n",
      " |  has_melody : bool\n",
      " |      True if multitrack has at least one melody stem\n",
      " |  predominant_stem : Track or None\n",
      " |      Track object for the predominant stem if availalbe, otherwise None\n",
      " |  dataset_version : string\n",
      " |      Iteration a multitrack came from.\n",
      " |      (E.g. \"V1\" for MedleyDB dataset_version 1,\n",
      " |      \"V2\" for MedleyDB dataset_version 2)\n",
      " |  _stem_activations : np.array\n",
      " |      Matrix of stem activations\n",
      " |  _stem_activations_idx : dictionary\n",
      " |      Dictionary mapping stem index to column of the stem_activations matrix\n",
      " |  _meta_path : str\n",
      " |      Path to metadata file.\n",
      " |  _stem_dir_path : str\n",
      " |      Path to multitrack's stem file directory\n",
      " |  _raw_dir_path : str\n",
      " |      Path to multitrack's raw file directory\n",
      " |  _stem_fmt : str\n",
      " |      Format of stem file basenames\n",
      " |  _raw_fmt : str\n",
      " |      format of raw file basenames\n",
      " |  _metadata : dict\n",
      " |      dictionary of data loaded from metadata file\n",
      " |  _melody1_annotation : np.array or None\n",
      " |      Melody 1 annotation if exists, otherwise None\n",
      " |  _melody2_annotation : np.array or None\n",
      " |      Melody 2 annotation if exists, otherwise None\n",
      " |  _melody3_annotation : np.array or None\n",
      " |      Melody 3 annotation if exists, otherwise None\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |      >>> mtrack = Multitrack('LizNelson_Rainfall')\n",
      " |      >>> another_mtrack = Multitrack('ArtistName_TrackTitle')\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, track_id)\n",
      " |      MultiTrack object __init__ method.\n",
      " |  \n",
      " |  activation_conf_from_stem(self, stem_idx, version=None)\n",
      " |      Get activation confidence from given stem.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stem_idx : int\n",
      " |          stem index (eg. 2 for stem S02)\n",
      " |      version : str\n",
      " |          If 'v2', uses the version 2 annotations. Otherwise uses acitvation\n",
      " |          annotations from the original release.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      activation_confidence : list\n",
      " |          List of time, activation confidence pairs\n",
      " |  \n",
      " |  bass_stems(self)\n",
      " |      Get list of stems that contain bass.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bass_stems: list\n",
      " |          List of Track objects where component='bass'.\n",
      " |  \n",
      " |  melody_stems(self)\n",
      " |      Get list of stems that contain melody.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      melody_stems : list\n",
      " |          List of Track objects where component='melody'.\n",
      " |  \n",
      " |  num_raw(self)\n",
      " |      Number of raw audio files.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_raw : int\n",
      " |          Number of raw audio files.\n",
      " |  \n",
      " |  num_stems(self)\n",
      " |      Number of stems.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_stems : int\n",
      " |          Number of stems.\n",
      " |  \n",
      " |  raw_filepaths(self)\n",
      " |      Get list of filepaths to raw audio files.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      raw_fpaths : list\n",
      " |          List of filepaths to raw audio files.\n",
      " |  \n",
      " |  stem_filepaths(self)\n",
      " |      Get list of filepaths to stem files.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stem_fpaths : list\n",
      " |          List of filepaths to stems.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  duration\n",
      " |      float: Duration of the mix\n",
      " |  \n",
      " |  melody1_annotation\n",
      " |      np.array: Melody 1 annotation.\n",
      " |  \n",
      " |  melody2_annotation\n",
      " |      np.array: Melody 2 annotation.\n",
      " |  \n",
      " |  melody3_annotation\n",
      " |      np.array: Melody 3 annotation.\n",
      " |  \n",
      " |  stem_activations\n",
      " |      np.array: Matrix of stem activations\n",
      " |  \n",
      " |  stem_activations_idx\n",
      " |      dictionary : Dictionary mapping stem index to column of the\n",
      " |      stem_activations matrix.\n",
      " |  \n",
      " |  stem_activations_idx_v2\n",
      " |      dictionary : Dictionary mapping stem index to column of the\n",
      " |      stem_activations matrix. (annotations version 2)\n",
      " |  \n",
      " |  stem_activations_v2\n",
      " |      np.array: Matrix of stem activations (annotations version 2)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_track(track_id):\n",
    "    t_gen = mdb.load_multitracks([track_id])\n",
    "    return next(t_gen)\n",
    "\n",
    "t = load_track('MusicDelta_Shadows')\n",
    "tr = Track(t)\n",
    "print(tr.stem_instruments)\n",
    "print(help(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    \"\"\" A track class invariant of medleyDBs multitrack. Contains information for pre-processing.\n",
    "    \n",
    "    To be used for pre-processing the minimal information needed is the following: \n",
    "        A trackID,\n",
    "        A dictionary mapping stems to instruments, \n",
    "        A file path to the .wav-file\n",
    "        And a path to the activation_conf file\n",
    "        \n",
    "    If a source_file doesn't exist it will be created in the pre-processing step. \n",
    "    \"\"\"\n",
    "    def __init__(self, track):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            track (medleydb.MultiTrack or str): Pass either a MultiTrack or the path of a mix.\n",
    "            data_type (str): To specify if the track should be used for training, testing, validation or non-labeled.\n",
    "        \"\"\"\n",
    "        if isinstance(track, mdb.MultiTrack):\n",
    "            self.track_id = track.track_id\n",
    "            \n",
    "            self.instruments, self.stem_instruments = self.extract_instruments(track)\n",
    "            assert len(self.instruments) > 0, \"no valid instruments in song\"\n",
    "            \n",
    "            assert os.path.exists(track.mix_path), \"%s does not exist\" % track.mix_path\n",
    "            self.mix_path = track.mix_path\n",
    "                \n",
    "            if os.path.exists(track.activation_conf_v2_fpath):   \n",
    "                self.activation_conf_path = track.activation_conf_v2_fpath\n",
    "            elif os.path.exists(track.activation_conf_fpath): \n",
    "                self.activation_conf_path = track.activation_conf_fpath\n",
    "            else: \n",
    "                raise Exception(\"no activation_conf files found\")\n",
    "            \n",
    "            # If no source, we create it in preprocessing step\n",
    "            if os.path.exists(os.path.join(SOURCE_PATH, \"%s.csv\" % self.track_id)): \n",
    "                self.source_path = os.path.join(SOURCE_PATH, \"%s.csv\" % self.track_id)\n",
    "            else:\n",
    "                self.source_path = None\n",
    "            \n",
    "            self.is_medley = True\n",
    "                \n",
    "        else: \n",
    "            self.track_id = track\n",
    "            \n",
    "            # TODO\n",
    "            assert os.path.exists(os.path.join(MIX_PATH, track, \"metadata.npy\")), \"%s does not exist\" % os.path.join(MIX_PATH, track, \"metadata.npy\")\n",
    "            self.stem_instruments = np.load(os.path.join(MIX_PATH, track, \"stem_instruments.npy\"), allow_pickle=True).item() \n",
    "            \n",
    "            # TODO \n",
    "            assert os.path.exists(os.path.join(MIX_PATH, track, \"%s.wav\" % track)), \"%s does not exist\" % os.path.join(MIX_PATH, track, \"%s.wav\"%track) \n",
    "            self.mix_path = os.path.join(MIX_PATH, track, \"%s.wav\" % track)\n",
    "            \n",
    "            # TODO \n",
    "            assert os.path.exists(os.path.join(MIX_PATH, track, \"activation_conf.csv\")), \"%s does not exist\" % os.path.join(MIX_PATH, track, \"activation_conf.csv\")  \n",
    "            self.activation_conf_path = os.path.join(MIX_PATH, track, \"activation_conf.csv\")\n",
    "            \n",
    "            # TODO \n",
    "            if os.path.exists(os.path.join(SOURCE_PATH,  \"%s.csv\" % track)):\n",
    "                self.source_path = os.path.join(SOURCE_PATH,  \"%s.csv\" % track)\n",
    "            else:\n",
    "                self.source_path = None\n",
    "                \n",
    "            self.is_medley = False\n",
    "        \n",
    "    def medleys_to_openmic(self, instruments):\n",
    "        return [MEDLEY_TO_OPENMIC[i] for i in instruments if i in MEDLEY_TO_OPENMIC.keys()]\n",
    "    \n",
    "    def extract_instruments(self, t):\n",
    "        instruments = {MEDLEY_TO_OPENMIC[i] for i in t.stem_instruments if i in MEDLEY_TO_OPENMIC.keys()}\n",
    "        stem_instruments = {self.generate_stem_key(k): self.medleys_to_openmic(v.instrument) for k, v in t.stems.items() if len(set(v.instrument).intersection(MEDLEY_TO_OPENMIC.keys())) > 0}\n",
    "        return instruments, stem_instruments\n",
    "    \n",
    "    def generate_stem_key(self, x):\n",
    "        if x < 10:\n",
    "            return \"S0%d\" % x\n",
    "        else:\n",
    "            return \"S%d\" % x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(x):\n",
    "    return str(x).rjust(5, \"0\") \n",
    "\n",
    "def generate_stem_key(x):\n",
    "    if x < 10:\n",
    "        return \"S0%d\" % x\n",
    "    else:\n",
    "        return \"S%d\" % x\n",
    "\n",
    "def create_spectrogram(track, spectrogram_len, n_fft, hop_length, n_mels):\n",
    "    y, sr = librosa.load(track.mix_path)\n",
    "    samples_per_spectrogram = int(sr*spectrogram_len)\n",
    "    num_spectrograms = len(y)//samples_per_spectrogram \n",
    "    # Remove samples that doesn't divide equally with s_p_s\n",
    "    y = y[:num_spectrograms*samples_per_spectrogram]\n",
    "    spectrograms = []\n",
    "    # could optimize by saving spectrograms directly here\n",
    "    # however imo code is cleaner if saved in helper func\n",
    "    for i in range(0, len(y), samples_per_spectrogram):\n",
    "        sound_bite = y[i:i+samples_per_spectrogram]\n",
    "        S = librosa.feature.melspectrogram(y=sound_bite, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "        spectrograms.append(S_dB)    \n",
    "    spectrograms = np.stack(spectrograms, axis=0)\n",
    "    return spectrograms\n",
    "    \n",
    "def create_labels(t, num_spectrograms, spectrogram_len=1):\n",
    "    time_cutoff = num_spectrograms*spectrogram_len\n",
    "    #Rows = which spectrogram, Cols = Which instrument\n",
    "    instrument_annotations = np.zeros((num_spectrograms, len(INSTRUMENTS)))\n",
    "    annotations = pd.read_csv(t.source_path)\n",
    "    for index, row in annotations.iterrows():\n",
    "        instrument = row[\"instrument_label\"]\n",
    "        if instrument in INSTRUMENTS:\n",
    "            s_t = row[\"start_time\"]\n",
    "            e_t = row[\"end_time\"]\n",
    "            if e_t > time_cutoff: \n",
    "                e_t = time_cutoff\n",
    "            d_t = e_t - s_t\n",
    "            s_i = int(s_t//spectrogram_len)\n",
    "            e_i = int(e_t//spectrogram_len)\n",
    "            #print(\"instrument: \", instrument, \"(%s)\" % INSTRUMENT_INDEX[instrument])\n",
    "            #print(\"start index: \", s_i)\n",
    "            #print(\"end index: \", e_i, \"\\n\") \n",
    "            for i in range(s_i, e_i):\n",
    "                instrument_annotations[i][INSTRUMENT_INDEX[instrument]] = 1\n",
    "    return instrument_annotations\n",
    "\n",
    "def create_matrix_labels(t, sr, num_spectrograms, spectrogram_len=1, hop_length=512):\n",
    "    time_cutoff = num_spectrograms*spectrogram_len\n",
    "    time_resolution = (hop_length/sr)\n",
    "    #Rows = which spectrogram, Cols = Which instrument\n",
    "    instrument_annotations = np.zeros(((num_spectrograms*spectrogram_len)//time_resolution), len(INSTRUMENTS))\n",
    "    annotations = pd.read_csv(t.source_path)\n",
    "    for index, row in annotations.iterrows():\n",
    "        instrument = row[\"instrument_label\"]\n",
    "        if instrument in INSTRUMENTS:\n",
    "            s_t = row[\"start_time\"]\n",
    "            e_t = row[\"end_time\"]\n",
    "            if e_t > time_cutoff: \n",
    "                e_t = time_cutoff\n",
    "            s_i = int(s_t//time_resolution)\n",
    "            e_i = int(e_t//time_resolution)\n",
    "            #print(\"instrument: \", instrument, \"(%s)\" % INSTRUMENT_INDEX[instrument])\n",
    "            #print(\"start index: \", s_i)\n",
    "            #print(\"end index: \", e_i, \"\\n\") \n",
    "            for i in range(s_i, e_i):\n",
    "                instrument_annotations[i][INSTRUMENT_INDEX[instrument]] = 1\n",
    "    return instrument_annotations\n",
    "    \n",
    "    \n",
    "def create_source_ids(t): \n",
    "    conf_df = pd.read_csv(t.activation_conf_path)\n",
    "    columns = conf_df.columns\n",
    "    num_instruments = len(columns)\n",
    "    start_time = [0] * num_instruments\n",
    "    new_bin = [False] * num_instruments\n",
    "    source_activations = [] \n",
    "    s_i = t.stem_instruments\n",
    "    for index, row in conf_df.iterrows():\n",
    "        time = row[0]\n",
    "        stem = 1\n",
    "        for conf in row[1:]:\n",
    "            # check for stems not included after relabeling\n",
    "            if not columns[stem] in s_i.keys():\n",
    "                stem += 1 \n",
    "                continue \n",
    "            if not conf >= 0.5 and new_bin[stem]:\n",
    "                new_bin[stem] = False\n",
    "                for instrument_label in s_i[columns[stem]]: \n",
    "                    source_activations.append((start_time[stem], time-0.0464, instrument_label))\n",
    "            if conf >= 0.5 and not new_bin[stem]:\n",
    "                new_bin[stem] = True\n",
    "                start_time[stem] = time\n",
    "            stem += 1\n",
    "            \n",
    "    source_df = pd.DataFrame(source_activations, columns=['start_time', 'end_time', 'instrument_label']) \n",
    "    source_df = source_df.sort_values(by=['instrument_label'])  \n",
    "    \n",
    "    source_df.to_csv(path_or_buf = os.path.join(SOURCE_PATH, \"%s.csv\" % t.track_id), index=False, float_format='%.4f')\n",
    "    t.source_path = os.path.join(SOURCE_PATH, \"%s.csv\" % t.track_id)\n",
    "\n",
    "def preprocess_track(track, dataset_type, spectrogram_len=1, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    spectrograms = create_spectrogram(track, spectrogram_len, n_fft, hop_length, n_mels)\n",
    "    number_of_spectrograms = spectrograms.shape[0]\n",
    "   \n",
    "    if track.source_path is None:\n",
    "        print(\"Yo\")\n",
    "        create_source_ids(track)\n",
    "\n",
    "    labels = create_labels(track, number_of_spectrograms, spectrogram_len)\n",
    "\n",
    "    base_path = os.path.join(DATA_PATH, \"%d_%d_%d_%d\" % (spectrogram_len, n_fft, hop_length, n_mels))\n",
    "    input_path = os.path.join(base_path, dataset_type, \"input\")\n",
    "    label_path = os.path.join(base_path, dataset_type, \"labels\")\n",
    "    \n",
    "    if not(os.path.exists(input_path)):\n",
    "        os.makedirs(input_path)  \n",
    "    \n",
    "    if not(os.path.exists(label_path)):\n",
    "        os.makedirs(label_path)  \n",
    "    \n",
    "    for i in range(number_of_spectrograms):\n",
    "        spectrogram = spectrograms[i]\n",
    "        label = labels[i]\n",
    "        # Don't save all 0 labels \n",
    "        #if sum(label) > 0: \n",
    "            # Each spectrogram with corresponding label will look like \"trackid_idx_mel/label\"\n",
    "        np.save(os.path.join(input_path, \"%s_%s.npy\" % (track.track_id, generate_id(i))), spectrogram)\n",
    "        np.save(os.path.join(label_path, \"%s_%s.npy\" % (track.track_id, generate_id(i))), label)\n",
    "\n",
    "def create_train_val_test_split(tracks, test_size = 0.2, val_size = 0.2):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for t in tracks: \n",
    "        X.append(t)\n",
    "        Y.append(list(t.instruments))\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(list(INSTRUMENTS))\n",
    "    Y = mlb.fit_transform(Y)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    test_train = MultilabelStratifiedShuffleSplit(n_splits=2, test_size = test_size, random_state=0)\n",
    "    \n",
    "    for train_index, test_index in test_train.split(X, Y):\n",
    "        X_train, test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        break\n",
    "    \n",
    "    train_val = MultilabelStratifiedShuffleSplit(n_splits=2, test_size = val_size, random_state=0)\n",
    "\n",
    "    for train_index, test_index in train_val.split(X_train, Y_train):\n",
    "        train, val = X_train[train_index], X_train[test_index]\n",
    "        train_labels, val_labels = Y_train[train_index], Y_train[test_index]\n",
    "        break\n",
    "        \n",
    "    print(\"Training sample length:\", train.shape[0])\n",
    "    print(\"Distribution:\", np.sum(train_labels, axis=0))\n",
    "    print(\"Validation sample length:\", val.shape[0])\n",
    "    print(\"Distribution:\", np.sum(val_labels, axis=0))\n",
    "    print(\"Test sample length\", test.shape[0])\n",
    "    print(\"Distribution:\", np.sum(Y_test, axis=0))\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "def create_tracks_from_medley(dataset_version):\n",
    "    tracks = []\n",
    "    unloaded_tracks = []\n",
    "    loadable = 0 \n",
    "    song_count = 0\n",
    "    for t in mdb.load_all_multitracks(dataset_version): \n",
    "        song_count += 1\n",
    "        try:\n",
    "            tracks.append(Track(t))\n",
    "        except: \n",
    "            unloaded_tracks.append(t.track_id)\n",
    "            continue\n",
    "        loadable += 1\n",
    "    print(\"Loaded %s/%s tracks\" % (loadable, song_count))\n",
    "    return tracks, unloaded_tracks\n",
    "\n",
    "def preprocess_tracks(test_size = 0.2, val_size = 0.2, dataset_version = ['V1', 'V2'], path_to_mixes = None):\n",
    "    tracks, _ = create_tracks_from_medley(dataset_version)\n",
    "    \n",
    "    # TODO: APPEND MIX-TRACKS\n",
    "    \n",
    "    train, val, test = create_train_val_test_split(tracks, test_size = test_size, val_size = val_size)\n",
    "    count = 0 \n",
    "    for t in train:\n",
    "        preprocess_track(t, \"train\")\n",
    "        count += 1 \n",
    "        print(\"Processing: %s/%s\" % (count, len(tracks)), end=\"\\r\")\n",
    "    for t in val:\n",
    "        preprocess_track(t, \"validation\")\n",
    "        count += 1 \n",
    "        print(\"Processing: %s/%s\" % (count, len(tracks)), end=\"\\r\")\n",
    "    for t in test: \n",
    "        preprocess_track(t, \"test\")\n",
    "        count += 1 \n",
    "        print(\"Processing: %s/%s\" % (count, len(tracks)), end=\"\\r\")\n",
    "        \n",
    "    # TODO: PREPROCESS MIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlnys/data/medleydb/medleydb/multitrack.py:367: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  metadata = yaml.load(f_in)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 144/196 tracks\n",
      "Training sample length: 90\n",
      "Distribution: [55 61 49 52 40 18  8  7  5 11  8  6  4  2  8 11]\n",
      "Validation sample length: 23\n",
      "Distribution: [14 15 12 13 10  5  2  2  1  3  2  1  1  1  2  3]\n",
      "Test sample length 31\n",
      "Distribution: [18 22 19 16 12  6  3  2  1  3  2  2  1  1  2  4]\n",
      "Processing: 1/144\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlnys/.local/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 144/144\r"
     ]
    }
   ],
   "source": [
    "preprocess_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_tracks = mdb.get_files_for_instrument('viola')\n",
    "tracks = mdb.load_multitracks(fx_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = next(fx_tracks)\n",
    "#play_stem(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carlnys/data/medleydb/medleydb/Audio/EthanHein_GirlOnABridge/EthanHein_GirlOnABridge_STEMS/EthanHein_GirlOnABridge_STEM_04.wav\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
