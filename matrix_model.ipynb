{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 256\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import sigmoid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import medleydb as mdb\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib notebook\n",
    "\n",
    "HOME_PATH = os.path.expanduser(\"~\")\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'data', 'preprocessed')\n",
    "\n",
    "OPENMIC_TO_MEDLEY = {\"drums\" : [\"drum set\"],\n",
    "                     \"bass\" : [\"electric bass\", \"double bass\"],\n",
    "                     \"guitar\" : [\"distorted electric guitar\", \"clean electric guitar\", \"acoustic guitar\"], \n",
    "                     \"voice\" : [\"male singer\", \"female singer\", \"male speaker\", \"female speaker\",\n",
    "                                \"male rapper\", \"female rapper\", \"beatboxing\", \"vocalists\", \"choir\",\n",
    "                                \"male screamer\", \"female screamer\"], \n",
    "                     \"piano\" : [\"piano\", \"tack piano\", \"electric piano\"],\n",
    "                     \"synthesizer\" : [\"synthesizer\"],\n",
    "                     #\"organ\" : [\"pipe organ\", \"electric organ\"],\n",
    "                     #\"accordion\" : [\"accordion\"],\n",
    "                     #\"banjo\" : [\"banjo\"], \n",
    "                     \"cello\" : [\"cello\", \"cello section\"], \n",
    "                     \"clarinet\" : [\"clarinet\", \"clarinet section\", \"bass clarinet\"], \n",
    "                     \"cymbals\" : [\"cymbal\"],\n",
    "                     \"flute\" : [\"flute\", \"dizi\", \"flute\", \"flute section\", \"piccolo\",\n",
    "                                \"bamboo flute\", \"panpipes\", \"recorder\"],\n",
    "                     \"mallet_percussion\" : [\"xylophone\", \"vibraphone\", \"glockenspiel\", \"marimba\"],\n",
    "                     \"mandolin\" : [\"mandolin\"],\n",
    "                     \"saxophone\": [\"alto saxophone\", \"baritone saxophone\", \"tenor saxophone\", \"soprano saxophone\"], \n",
    "                     \"trombone\": [\"trombone\", \"trombone section\"], \n",
    "                     \"trumpet\" : [\"trumpet\", \"trumpet section\"],\n",
    "                     #\"ukulele\" : [\"ukulele\"], \n",
    "                     \"violin\" : [\"violin\", \"violin seciton\"]} \n",
    "\n",
    "INSTRUMENTS = OPENMIC_TO_MEDLEY.keys()\n",
    "INSTRUMENT_INDEX = {key : i for i, (key, _) in enumerate(OPENMIC_TO_MEDLEY.items())}\n",
    "\n",
    "MEDLEY_TO_OPENMIC = {v: k for k, v_list in OPENMIC_TO_MEDLEY.items() for v in v_list}\n",
    "MEDLEY_TO_INDEX = {k: INSTRUMENT_INDEX[v] for k, v in MEDLEY_TO_OPENMIC.items()}\n",
    "REV_INSTRUMENT_INDEX = {v: k for k, v in INSTRUMENT_INDEX.items()}\n",
    "\n",
    "NUM_LABELS = len(INSTRUMENTS)\n",
    "\n",
    "spectrogram_params = {'sample_rate' : 16000,\n",
    "                      'spectrogram_len' : 8.191,\n",
    "                      'n_fft' : 1024,\n",
    "                      'hop_length' : 512,\n",
    "                      'n_mels' : 128}\n",
    "\n",
    "def play_medley_audio(track):\n",
    "    track_id = load_track(track).mix_path\n",
    "    samples, sample_rate = librosa.load(track_id)\n",
    "    ipd.display(ipd.Audio(samples, rate=sample_rate, autoplay=True))\n",
    "\n",
    "def play_audio(track):\n",
    "    homedir = os.path.expanduser(\"~\")\n",
    "    path = os.path.join(homedir, \"data/es_data\", track)\n",
    "    samples, sample_rate = librosa.load(path)\n",
    "    ipd.display(ipd.Audio(samples, rate=sample_rate, autoplay=True))\n",
    "    \n",
    "def load_track(track_id):\n",
    "    t_gen = mdb.load_multitracks([track_id])\n",
    "    return next(t_gen)\n",
    "\n",
    "def display_spectrogram(s, p):\n",
    "    librosa.display.specshow(s, x_axis='time',\n",
    "                 y_axis='mel', sr=p['sample_rate'],\n",
    "                 hop_length=p['hop_length'])\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def display_chromagram(s):\n",
    "    chroma = librosa.feature.chroma_stft(y=s, sr=22050)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('Chromagram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_conv_output(input_dim, filter_size, stride, padding):\n",
    "    print((input_dim[0]+(2*padding[0])-filter_size[0])//stride[0] + 1, (input_dim[1]+(2*padding[1])-filter_size[1])//stride[1] + 1)\n",
    "    \n",
    "calculate_conv_output([1,256], [1,1], [1,1], [0,0])\n",
    "\n",
    "def calculate_pool_output(input_dim, pool_size, stride):\n",
    "    h = (input_dim[0]-pool_size[0])/stride[0] + 1\n",
    "    w = (input_dim[1]-pool_size[1])/stride[1] + 1\n",
    "    print(h,w)\n",
    "    return [h,w]\n",
    "    \n",
    "def pooling_helper(input_dim, pools):\n",
    "    for pool in pools:\n",
    "        input_dim = calculate_pool_output(input_dim, pool, pool)\n",
    "        \n",
    "#pooling_helper([128,256], [[2,1],[4,1],[4,1],[1,1]])\n",
    "    \n",
    "def plot_loss(train_score, val_score):\n",
    "    plt.plot(train_score)\n",
    "    plt.plot(val_score)\n",
    "    plt.show()\n",
    "\n",
    "# Takes (instruments, predictions) np-array which plots the predictions neatly\n",
    "def visualize_song_predictions(predictions):\n",
    "    cmap = mpl.colors.ListedColormap(['white','black'])\n",
    "    bounds = [0,0,1,1]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    instrument_activations = np.transpose(predictions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    #fig.set_size_inches(30,20)\n",
    "    plt.yticks(np.arange(0,17, step=1))\n",
    "    plt.xticks(np.arange(0,len(predictions), step=5))\n",
    "    labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "    labels = [REV_INSTRUMENT_INDEX[x] for x in range(predictions.shape[1])]\n",
    "    ax.set_yticklabels(labels)\n",
    "    #pyplot.yticks([REV_INSTRUMENT_INDEX[x] for x in range(18)])\n",
    "    img = plt.imshow(instrument_activations,\n",
    "                        interpolation='nearest',\n",
    "                        cmap=cmap,\n",
    "                        aspect='auto')\n",
    "    \n",
    "def test_model_on_non_medley(model, path):\n",
    "    model.eval()\n",
    "    test_data_path = os.path.join(HOME_PATH, path)\n",
    "    #test_data_path = os.path.join(homedir, \"data/processed/non_medley/1_2048_512/lofi\")\n",
    "    test_inputs = NonLabeled(test_data_path, debug=True)\n",
    "    test_inputs_loader = iter(DataLoader(test_inputs, batch_size=1, shuffle=False))\n",
    "    \n",
    "    predictions = []\n",
    "    for f, s in test_inputs_loader:\n",
    "        s = s.cuda()\n",
    "        output = model(s)\n",
    "        predictions.append((sigmoid(output) > 0.5).float().cpu().numpy()[0])\n",
    "    predictions = np.array(predictions)\n",
    "    visualize_song_predictions(predictions)\n",
    "    split_path = path.split(\"/\")\n",
    "    track_name = split_path[-1]\n",
    "    play_audio(\"%s.wav\" % track_name)\n",
    "    #labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "    #labels[0] = 'Testing'\n",
    "    #ax.set_yticklabels(labels)\n",
    "    #return predictions\n",
    "    #np.set_printoptions(threshold=sys.maxsize)\n",
    "    #print(np.transpose(predictions))\n",
    "    #print(predictions)\n",
    "    #f, s  = next(test_inputs_loader)\n",
    "    #s = s.numpy()[0][0]\n",
    "    #print(s.shape)\n",
    "    #display_spectrogram(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedleyDB(Dataset):\n",
    "    def __init__(self, base_path, input_transform=None, train=True, debug=False):\n",
    "        self.base_path = base_path\n",
    "        self.input_path = os.path.join(base_path, \"input\")\n",
    "        self.label_path = os.path.join(base_path, \"matrix_labels\")\n",
    "        self.inputs = os.listdir(self.input_path)\n",
    "        self.debug = debug\n",
    "    def __getitem__(self, idx):\n",
    "        input_file_name = self.inputs[idx]\n",
    "        spectrogram = np.load(os.path.join(self.input_path, input_file_name))\n",
    "        label = np.load(os.path.join(self.label_path, input_file_name))\n",
    "        if self.debug:\n",
    "            return input_file_name, spectrogram, label\n",
    "        else:\n",
    "            #return spectrogram, label\n",
    "            return np.expand_dims(spectrogram, axis=0), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "class NonLabeled(Dataset):\n",
    "    def __init__(self, base_path, input_transform=None, train=True, debug=False):\n",
    "        self.base_path = base_path\n",
    "        self.input_path = os.path.join(base_path, \"input\")\n",
    "        self.inputs = os.listdir(self.input_path)\n",
    "        self.inputs.sort()\n",
    "        self.debug = debug\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        input_file_name = self.inputs[idx]\n",
    "        spectrogram = np.load(os.path.join(self.input_path, input_file_name))\n",
    "        if self.debug:\n",
    "            return input_file_name, np.expand_dims(spectrogram, axis=0)\n",
    "        else:\n",
    "            return np.expand_dims(spectrogram, axis=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "spec_folder = \"%d_%d_%d_%d\" % (int(spectrogram_params['spectrogram_len']),\n",
    "                                spectrogram_params['n_fft'],              \n",
    "                                spectrogram_params['hop_length'],\n",
    "                                spectrogram_params['n_mels'])\n",
    "        \n",
    "TRAIN_PATH = os.path.join(DATA_PATH, spec_folder, \"train\")\n",
    "VAL_PATH = os.path.join(DATA_PATH, spec_folder, \"validation\")\n",
    "TEST_PATH = os.path.join(DATA_PATH, spec_folder, \"test\")\n",
    "\n",
    "train_data = MedleyDB(TRAIN_PATH)\n",
    "validation_data = MedleyDB(VAL_PATH)\n",
    "test_data = MedleyDB(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train = DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "validation = DataLoader(validation_data, batch_size=batch_size, shuffle = True) \n",
    "test = DataLoader(test_data, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that data seems OK \n",
    "#\n",
    "#data_loader = iter(train)\n",
    "#s, l = next(data_loader)\n",
    "#s = s.numpy()[0]\n",
    "#print(s.shape)\n",
    "#l = l.numpy()[0]\n",
    "#print(l.shape)\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(len(l[0]))\n",
    "#display_spectrogram(s[0], spectrogram_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"In order to preserve spatial dimensions,\n",
    "# stride of 1 and Same zero-padding scheme is used for all\n",
    "# the convolutional layers. Each Conv2D layer is followed by\n",
    "# batch-normalization [16] and the Exponential Linear Unit\n",
    "# (ELU) [7] activation function.\"\"\n",
    "# \n",
    "# Conv Block 1, convolve and downsample\n",
    "# Pixels: 128x44 -> 64x22\n",
    "# Channels: 1 -> 64\n",
    "# Max-Pool 2x2 \n",
    "#\n",
    "# Conv Block 2, convolve and downsample\n",
    "# Pixels: 64x22 -> 32x11\n",
    "# Channels: 64 -> 128\n",
    "# Max-Pool 2x2\n",
    "#\n",
    "# Conv Block 3, convolve and downsample\n",
    "# Pixels: 32x12 ->  10x4 \n",
    "# Channels: 128 -> 256\n",
    "# Max-Pool 3x3\n",
    "#\n",
    "# Conv Block 4, convolve and downsample\n",
    "# Pixels:  10x4 > 3x1\n",
    "# Channels: 256 -> 640\n",
    "# Max-Pool 3x3\n",
    "#\n",
    "# Flatten: 3*1*640 = 1920\n",
    "# FC (1920 -> 128)\n",
    "# FC (128 -> 18)\n",
    "\n",
    "# REMEMBER TO USE SIGMOID ON OUTPUTS WHEN TESTING BECAUSE LOSS WILL \n",
    "# AUTOMATICALLY SIGMOID THE RESULTS FOR US\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # We only pool on the freq. axis\n",
    "        self.pool_2x1 = nn.MaxPool2d([2,1])\n",
    "        self.pool_4x1 = nn.MaxPool2d([4,1])\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                                 out_channels = 64,\n",
    "                                 kernel_size = 3,\n",
    "                                 stride = 1,\n",
    "                                 padding = 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 64,\n",
    "                                 out_channels = 128,\n",
    "                                 kernel_size = 3,\n",
    "                                 stride = 1,\n",
    "                                 padding = 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = 128,\n",
    "                                 out_channels = 256,\n",
    "                                 kernel_size = 3,\n",
    "                                 stride = 1,\n",
    "                                 padding = 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels = 256,\n",
    "                                 out_channels = 512,\n",
    "                                 kernel_size = 3,\n",
    "                                 stride = 1,\n",
    "                                 padding = 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels = 512,\n",
    "                         out_channels = 16,\n",
    "                         kernel_size = 1,\n",
    "                         stride = 1,\n",
    "                         padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = F.relu(self.pool_2x1(self.conv1_bn(self.conv1(x))))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.pool_4x1(self.conv2_bn(self.conv2(x))))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.pool_4x1(self.conv3_bn(self.conv3(x))))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.pool_4x1(self.conv4_bn(self.conv4(x))))\n",
    "        #print(x.shape)\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        #(batch x classes x 1 x time) -> (batch x classes x time)\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[3])\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "   \n",
    "    # torch.Size([8, 64, 64, 256])\n",
    "    # torch.Size([8, 128, 16, 256])\n",
    "    # torch.Size([8, 256, 4, 256])\n",
    "    # torch.Size([8, 512, 1, 256])\n",
    "    # torch.Size([8, 16, 1, 256])\n",
    "    # torch.Size([8, 16, 256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = torch.cuda.is_available()\n",
    "lr = 0.001\n",
    "batch_size = batch_size\n",
    "model = Net()\n",
    "params = model.parameters()\n",
    "# Binary Cross-Entropy Loss\n",
    "if gpu_available:\n",
    "    model.cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr)    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)    \n",
    "n_epochs = 15\n",
    "len_data = len(train.dataset)\n",
    "num_batches = len_data//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#for batch_idx, (data, target) in enumerate(train):\n",
    "#    out = model.forward(data.cuda())\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    validation_loss_min = sys.maxsize\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train):\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, num_batches), end=\"\\r\")\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if gpu_available:\n",
    "                data, target = data.float().cuda(), target.float().cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            #print(data.shape)\n",
    "            output = model(data)\n",
    "            #print(output.shape)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss, loss.item is the avarage loss of the batch.\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            ######################    \n",
    "            # validate the model #\n",
    "            ######################\n",
    "        model.eval()\n",
    "        for data, target in validation:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if gpu_available:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            validation_loss += loss.item()*data.size(0)\n",
    "                \n",
    "         # calculate average losses\n",
    "        train_loss = train_loss/len(train.sampler)\n",
    "        validation_loss = validation_loss/len(validation.sampler)\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "        plot_loss(train_losses, validation_losses)\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, train_loss, validation_loss))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if validation_loss <= validation_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            validation_loss_min,\n",
    "            validation_loss))\n",
    "            torch.save(model.state_dict(), 'matrix_label_model.pt')\n",
    "            validation_loss_min = validation_loss\n",
    "            \n",
    "    torch.save(model.state_dict(), 'overfit_matrix_label_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15\n",
      "Epoch: 1 \tTraining Loss: 0.336586 \tValidation Loss: 0.298232\n",
      "Validation loss decreased (9223372036854775808.000000 --> 0.298232).  Saving model ...\n",
      "Epoch: 2/15\n",
      "Epoch: 2 \tTraining Loss: 0.256025 \tValidation Loss: 0.284466\n",
      "Validation loss decreased (0.298232 --> 0.284466).  Saving model ...\n",
      "Epoch: 3/15\n",
      "Epoch: 3 \tTraining Loss: 0.231719 \tValidation Loss: 0.289287\n",
      "Epoch: 4/15\n",
      "Epoch: 4 \tTraining Loss: 0.220319 \tValidation Loss: 0.276486\n",
      "Validation loss decreased (0.284466 --> 0.276486).  Saving model ...\n",
      "Epoch: 5/15\n",
      "Epoch: 5 \tTraining Loss: 0.204597 \tValidation Loss: 0.282794\n",
      "Epoch: 6/15\n",
      "Epoch: 6 \tTraining Loss: 0.195866 \tValidation Loss: 0.272377\n",
      "Validation loss decreased (0.276486 --> 0.272377).  Saving model ...\n",
      "Epoch: 7/15\n",
      "Epoch: 7 \tTraining Loss: 0.186761 \tValidation Loss: 0.307465\n",
      "Epoch: 8/15\n",
      "Epoch: 8 \tTraining Loss: 0.180193 \tValidation Loss: 0.294125\n",
      "Epoch: 9/15\n",
      "Epoch: 9 \tTraining Loss: 0.174610 \tValidation Loss: 0.290962\n",
      "Epoch: 10/15\n",
      "Epoch: 10 \tTraining Loss: 0.167229 \tValidation Loss: 0.302329\n",
      "Epoch: 11/15\n",
      "Epoch: 11 \tTraining Loss: 0.164331 \tValidation Loss: 0.331690\n",
      "Epoch: 12/15\n",
      "Epoch: 12 \tTraining Loss: 0.159038 \tValidation Loss: 0.286538\n",
      "Epoch: 13/15\n",
      "Epoch: 13 \tTraining Loss: 0.153748 \tValidation Loss: 0.279827\n",
      "Epoch: 14/15\n",
      "Epoch: 14 \tTraining Loss: 0.149995 \tValidation Loss: 0.298070\n",
      "Epoch: 15/15\n",
      "Epoch: 15 \tTraining Loss: 0.147236 \tValidation Loss: 0.311000\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('matrix_label_model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD 50 epochs Relu: Epoch: 50 \tTraining Loss: 0.310960 \tValidation Loss: 0.312199\n",
    "Adam 50 epochs Relu: Epoch: 50 \tTraining Loss: 0.001489 \tValidation Loss: 0.074400\n",
    "                     Best: Validation loss decreased (0.074246 --> 0.073360).  Saving model ...\n",
    "     \n",
    "Without negatives: \n",
    "Epoch: 9 \tTraining Loss: 0.071606 \tValidation Loss: 0.294554\n",
    "Validation loss decreased (0.306978 --> 0.294554).  Saving model ...\n",
    "Epoch: 50 \tTraining Loss: 0.005509 \tValidation Loss: 0.522374\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO MANUALLY SIGMOID THE OUTPUTS SINCE THE LOSS DOES THAT FOR US\n",
    "# TODO: Don't hard-code number of classes\n",
    "#def test_model(model, num_batches=num_batches):\n",
    "#    model.eval()\n",
    "#    # track test loss\n",
    "#    test_loss = 0.0 \n",
    "#    # iterate over test data\n",
    "#    count = 0\n",
    "#    \n",
    "#    labels_total = torch.zeros(NUM_LABELS).cuda()\n",
    "#    correct_pred = torch.zeros(NUM_LABELS).cuda()\n",
    "#    \n",
    "#    for data, target in test:\n",
    "#        print(len(test))\n",
    "#        # move tensors to GPU if CUDA is available\n",
    "#        if gpu_available:\n",
    "#            data, target = data.cuda(), target.cuda()\n",
    "#            \n",
    "#        if count == 0: \n",
    "#            scores = torch.tensor([num_batches*len(test)])\n",
    "#            predictions = torch.tensor([])\n",
    "#            targets = torch.tensor([])\n",
    "#        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "#        output = model(data)\n",
    "#        # calculate the batch loss\n",
    "#        loss = criterion(output, target)\n",
    "#        # update test loss \n",
    "#        test_loss += loss.item()*data.size(0)\n",
    "#        # convert output probabilities to predicted class\n",
    "#        \n",
    "#        # Convert to score and use threshhold 0.5\n",
    "#        output = sigmoid(output)\n",
    "#        \n",
    "#        pred = (output > 0.5).float()\n",
    "#        # List concat, to be returned and used by scikit for metrics\n",
    "#       #for i in range(output.shape[0]):\n",
    "#       #    for j in range(output.shape[2]):\n",
    "#       #        scores = scores + list(output.data[i, :, j].cpu().numpy())\n",
    "#       #        predictions = predictions + list(pred[i, :, j].cpu().numpy())\n",
    "#       #        targets = targets + list(target.data[i, :, j].cpu().numpy())\n",
    "#       \n",
    "#        # compare predictions to true label\n",
    "#        correct = pred.eq(target.data.view_as(pred))\n",
    "#        true_positives = np.logical_and(pred.cpu().numpy(), correct.cpu().numpy())\n",
    "#        \n",
    "#        # Go through the batch, aggregate true positives\n",
    "#        for i in range(target.shape[0]):\n",
    "#            # Elementwise addition\n",
    "#            labels_total = np.add(labels_total, np.sum(target.data[i].cpu().numpy(), axis=1))\n",
    "#            correct_pred = np.add(correct_pred, np.sum(true_positives[i], axis=1))\n",
    "#            \n",
    "#        count += 1\n",
    "#\n",
    "#    # average test loss\n",
    "#    test_loss = test_loss/len(test)\n",
    "#    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "#    np.set_printoptions(suppress=True)\n",
    "#    print(labels_total)\n",
    "#    print(correct_pred)\n",
    "#    return np.array(scores), np.array(predictions), np.array(targets)\n",
    "#\n",
    "#scores, predictions, targets = test_model(model, num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 98293., 115541., 124584.,  60653.,  74214.,  39586.,  15183.,   2289.,\n",
      "           501.,   6664.,   1604.,  23396.,   2170.,    508.,   2715.,  22055.],\n",
      "       device='cuda:0')\n",
      "tensor([7.5141e+04, 1.0266e+05, 6.3808e+04, 3.6863e+04, 3.5114e+04, 5.2180e+03,\n",
      "        7.1680e+03, 0.0000e+00, 0.0000e+00, 8.1000e+01, 0.0000e+00, 3.9950e+03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0569e+04], device='cuda:0')\n",
      "Test Loss: 8.056275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# REMEMBER TO MANUALLY SIGMOID THE OUTPUTS SINCE THE LOSS DOES THAT FOR US\n",
    "# TODO: Don't hard-code number of classes\n",
    "def test_model(model, num_batches=num_batches):\n",
    "    model.eval()\n",
    "    # track test loss\n",
    "    test_loss = 0.0 \n",
    "    # iterate over test data\n",
    "    \n",
    "    labels_total = np.zeros(NUM_LABELS)\n",
    "    correct_pred = np.zeros(NUM_LABELS)\n",
    "    \n",
    "    labels_total_test = torch.zeros(NUM_LABELS).cuda()\n",
    "    correct_pred_test = torch.zeros(NUM_LABELS).cuda()\n",
    "    \n",
    "    scores = torch.zeros([0, 16]).cuda()\n",
    "    predictions = torch.zeros([0,16]).cuda()\n",
    "    targets = torch.zeros([0,16]).cuda()\n",
    "    \n",
    "    for idx, (data, target) in enumerate(test):\n",
    "        if gpu_available:\n",
    "            data, target = data.float().cuda(), target.float().cuda()\n",
    "            \n",
    "        #if idx == 0: \n",
    "        #    # init here since we get data dims\n",
    "        #    scores = torch.zeros([len(test.dataset)*target.shape[2], target.shape[1]])\n",
    "        #    predictions = torch.zeros([len(test.dataset)*target.shape[2], target.shape[1]])\n",
    "        #    targets = torch.zeros([len(test.dataset)*target.shape[2], target.shape[1]])\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        \n",
    "        # Convert to score and use threshhold 0.5\n",
    "        output = sigmoid(output)\n",
    "        \n",
    "        pred = (output > 0.5).float()\n",
    "        \n",
    "        scores = torch.cat([scores, output.data.permute(0,2,1).reshape(-1, 16)], dim=0)\n",
    "        predictions = torch.cat([predictions, pred.data.permute(0,2,1).reshape(-1, 16)], dim=0)\n",
    "        targets = torch.cat([targets, target.data.permute(0,2,1).reshape(-1, 16)], dim=0)\n",
    "       \n",
    "        # compare predictions to true label\n",
    "        correct = pred.eq(target.data.view_as(pred))\n",
    "        #true_positives = np.logical_and(pred.cpu().numpy(), correct.cpu().numpy())\n",
    "        true_positives = pred * correct\n",
    "        \n",
    "        labels_total_test = labels_total_test + torch.sum(target.permute(0,2,1).reshape(-1, 16), axis=0)\n",
    "        correct_pred_test = correct_pred_test + torch.sum(true_positives.permute(0,2,1).reshape(-1, 16), axis=0)\n",
    "\n",
    "        # Go through the batch, aggregate true positives\n",
    "        #for i in range(target.shape[0]):\n",
    "            # Elementwise addition\n",
    "            \n",
    "    # average test loss\n",
    "    test_loss = test_loss/len(test)\n",
    "    print(labels_total_test)\n",
    "    print(correct_pred_test)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    np.set_printoptions(suppress=True)\n",
    "    return scores.cpu().numpy(), predictions.cpu().numpy(), targets.cpu().numpy()\n",
    "\n",
    "#scores, predictions, targets = test_model(model, num_batches)\n",
    "scores, predictions, targets = test_model(model, num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]],\n",
      "\n",
      "        [[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]])\n",
      "tensor([[ 0, 10, 20],\n",
      "        [ 1, 11, 21],\n",
      "        [ 2, 12, 22],\n",
      "        [ 3, 13, 23],\n",
      "        [ 4, 14, 24],\n",
      "        [ 5, 15, 25],\n",
      "        [ 6, 16, 26],\n",
      "        [ 7, 17, 27],\n",
      "        [ 8, 18, 28],\n",
      "        [ 9, 19, 29],\n",
      "        [30, 40, 50],\n",
      "        [31, 41, 51],\n",
      "        [32, 42, 52],\n",
      "        [33, 43, 53],\n",
      "        [34, 44, 54],\n",
      "        [35, 45, 55],\n",
      "        [36, 46, 56],\n",
      "        [37, 47, 57],\n",
      "        [38, 48, 58],\n",
      "        [39, 49, 59]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(scores, predictions, targets):\n",
    "    f1_macro = metrics.f1_score(targets, predictions, average='macro')\n",
    "    f1_micro = metrics.f1_score(targets, predictions, average='micro')\n",
    "    lrap = metrics.label_ranking_average_precision_score(targets, scores)\n",
    "    auc_roc_micro = metrics.roc_auc_score(targets, scores, average='micro')\n",
    "    auc_roc_macro = metrics.roc_auc_score(targets, scores, average='macro')\n",
    "    precision, recall, f_score, support = metrics.precision_recall_fscore_support(targets, predictions, average=None)\n",
    "    #s = np.array([[0.5, 0.7, 0.3], [0.2, 0.5, 0.8], [0.2, 0.5, 0.8]])\n",
    "    #t = np.array([[1,1,1], [1,0,1], [0,1,0]])\n",
    "    #print(scores.shape)\n",
    "    #print(targets.shape)\n",
    "    print(\"F1-Macro:\", f1_macro)\n",
    "    print(\"F1-Micro:\", f1_micro)\n",
    "    print(\"lrap:\", lrap)\n",
    "    print(\"AUC-ROC-Macro:\", auc_roc_macro)\n",
    "    print(\"AUC-ROC-Micro:\", auc_roc_micro)\n",
    "    return {'f1_micro' : f1_micro,\n",
    "            'f1_macro' : f1_macro, \n",
    "            'lrap' : lrap, \n",
    "            'auc_roc_macro' : auc_roc_macro,\n",
    "            'auc_roc_micro' : auc_roc_micro, \n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'f_score' : f_score,\n",
    "            'support' : support}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206848, 16) (206848, 16) (206848, 16)\n",
      "F1-Macro: 0.3166896847423443\n",
      "F1-Micro: 0.6477730021680422\n",
      "lrap: 0.7835182741420872\n",
      "AUC-ROC-Macro: 0.7688768456377902\n",
      "AUC-ROC-Micro: 0.9218896804368768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracies = calculate_metrics(scores, predictions, targets)\n",
    "precision = accuracies['precision']\n",
    "recall = accuracies['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82223754 0.73646414 0.79769971 0.64385021 0.72212397 0.37707761\n",
      " 0.83290727 0.         0.         0.13170732 0.         0.72281527\n",
      " 0.         0.         0.         0.65112124]\n",
      "[0.76445932 0.88847249 0.5121685  0.60776878 0.47314523 0.13181428\n",
      " 0.47210696 0.         0.         0.01215486 0.         0.17075568\n",
      " 0.         0.         0.         0.47921106]\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(predictions[0:50,:])\n",
    "#print(targets[0:50, :])\n",
    "#\n",
    "#target = torch.arange(0, 60).reshape((2, 3, 10))   \n",
    "#\n",
    "#print(target)\n",
    "#print(target.permute((0, 2, 1)).reshape(-1,3))\n",
    "#print(target.reshape(-1, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
